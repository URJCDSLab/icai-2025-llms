{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f808480c",
   "metadata": {},
   "source": [
    "# Exploring Text Generation as a Threat\n",
    "\n",
    "This notebook explores how the text generation capabilities of Large Language Models (LLMs) can be used to attack targeted systems and models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004834e8",
   "metadata": {},
   "source": [
    "## Attacking Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c812a7",
   "metadata": {},
   "source": [
    "### Victim Model: Sentiment Classifier\n",
    "\n",
    "Consider a scenario in which the target system to attack is a sentiment analysis model that classifies input text based on its sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a52acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "clf(\"I love using these models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8d375",
   "metadata": {},
   "source": [
    "### LLM Attack: Perturbing Original Input\n",
    "\n",
    "LLMs can automate the process of generating adversarial attacks against this model.\n",
    "\n",
    "The adversarial attack modifies the text to deceive the target model while resembling the original input from a human perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549666b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Introduce typos into this text. Only answer the text with typos.\n",
    "\n",
    "Text: \"I love using these models!\"\n",
    "Answer:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"{prompt}\" | ollama run llama3:instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3734e",
   "metadata": {},
   "source": [
    "### Victim Model: Sentiment Classifier\n",
    "\n",
    "Introducing the perturbed text created by the LLM can cause the target victim system to produce incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511bb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "clf(\"I lov usin thse modles!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
